
# ArgoCD Architecture

ArgoCD is built with a modular and scalable architecture that ensures efficient and reliable GitOps-based deployments for Kubernetes. Its design is centered around several core components that collaborate to keep your Kubernetes clusters in sync with the desired state stored in Git.

## Core Components

- **API Server**:

    Acts as the central hub for user interactions. It exposes a RESTful interface that enables you to manage ArgoCD applications, view deployment statuses, and interact with the system through both a web UI and a CLI.

- **Repository Server**:

    Responsible for communicating with Git repositories. It retrieves the declarative configuration files and manifests that define the desired state of your applications, ensuring that the most up-to-date information is always available for synchronization.

- **Application Controller**:

    The engine of ArgoCD’s continuous delivery process. It continuously monitors your Kubernetes clusters to detect any drift from the desired state and automatically triggers the necessary actions to reconcile the differences, keeping your live environment aligned with what’s declared in Git.

- **Component Overview**

    ![alt text](https://argo-cd.readthedocs.io/en/latest/assets/argocd-components.png)

## How These Components Interact

- **Synchronization Workflow**:

    When a developer commits a change to a Git repository, the Repository Server fetches the new configuration data. The Application Controller then compares this desired state with the current state in the Kubernetes cluster. Meanwhile, the API Server provides real-time status updates and logs to the user interface, offering clear visibility into the synchronization process.

- **Feedback Loop**:

    The interaction among these components creates a continuous feedback loop. As soon as a discrepancy is detected, the Application Controller initiates corrective actions, and the API Server ensures that users are informed of the changes and the overall health of the deployment. This tight loop guarantees that any deviation from the expected state is quickly addressed.

## Resource Requirements and Scalability Considerations

- **Recommendations**:

    - There are no official requirements and recommendations from the community
    - Helm Chart

        | Component                     | CPU R/L     | Memory R/L
        | ---                           | ---:        | ---:
        | Application Controller        | 250m/500m   | 256Mi/512Mi
        | Application Set Controller    | 100m/100m   | 128Mi/128Mi
        | Dex                           | 10m/50m     | 32Mi/64Mi
        | Dex Init                      | 5m/10m      | 96Mi/144Mi
        | Redis                         | 100m/200m   | 64Mi/128Mi
        | Redis Init                    | 100m/200m   | 64Mi/128Mi
        | Redis Exporter                | 100m/200m   | 64Mi/128Mi
        | Server                        | 50m/100m    | 64Mi/128Mi
        | Server Extensions             | 10m/50m     | 64Mi/128Mi
        | Repository Server             | 10m/50m     | 64Mi/128Mi
        | Notifications Controller      | 100m/100m   | 128Mi/128Mi
        | Commit Server                 | 100m/100m   | 128Mi/128Mi
        |                               |             |
        | Total                         | 935m/1660m  | 1152Mi/1872Mi

- **Resource Requirements**:
    - API Server and Application Controller:<br>Typically require moderate CPU and memory resources to handle user requests and perform continuous state reconciliation.

    - Repository Server:<br>Needs sufficient network bandwidth and storage to manage Git data, especially when dealing with large or multiple repositories.

- **Scalability Considerations**:
    - Horizontal Scaling:<br>Each component, particularly the Application Controller, can be scaled out to handle an increasing number of applications and clusters, ensuring that performance remains consistent even under high loads.

    - High Availability:<br>Deploying ArgoCD in a high availability configuration eliminates single points of failure. This setup enhances resilience and ensures that deployments continue uninterrupted, even during peak usage or component failures.

    - Dynamic Resource Allocation:<br>Leveraging Kubernetes’ built-in scaling features allows you to dynamically adjust resources based on demand, ensuring that the system remains efficient as the scale of your operations grows.
